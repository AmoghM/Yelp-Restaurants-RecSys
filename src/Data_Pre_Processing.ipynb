{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6685900/6685900 [01:03<00:00, 104541.68it/s]\n",
      "100%|██████████| 192609/192609 [00:03<00:00, 51348.27it/s]\n",
      "100%|██████████| 1637138/1637138 [00:29<00:00, 56058.88it/s]\n"
     ]
    }
   ],
   "source": [
    "#Importing Review Data\n",
    "line_count = len(open(\"../data/review.json\").readlines())\n",
    "user_ids, business_ids, stars, dates = [], [], [], []\n",
    "with open(\"review.json\") as f:\n",
    "  for line in tqdm(f, total=line_count):\n",
    "       blob = json.loads(line)\n",
    "       user_ids += [blob[\"user_id\"]]\n",
    "       business_ids += [blob[\"business_id\"]]\n",
    "       stars += [blob[\"stars\"]]\n",
    "       dates += [blob[\"date\"]]\n",
    "ratings = pd.DataFrame(\n",
    "   {\"user_id\": user_ids, \"business_id\": business_ids, \"rating\": stars, \"date\": dates}\n",
    ")\n",
    "user_counts = ratings[\"user_id\"].value_counts()\n",
    "active_users = user_counts.loc[user_counts >= 5].index.tolist()\n",
    "\n",
    "\n",
    "business_counts = ratings[\"business_id\"].value_counts()\n",
    "popular_business = business_counts.loc[business_counts >= 5].index.tolist()\n",
    "\n",
    "\n",
    "\n",
    "#Importing Business data\n",
    "line_count = len(open(\"../data/business.json\").readlines())\n",
    "business_ids,name, city, avg_rating,review_cnt,categories, \\\n",
    "latitude, longitude, is_open, \\\n",
    "attributes  = [], [], [], [],[],[], [], [], [], []\n",
    "\n",
    "with open(\"business.json\") as f:\n",
    "  for line in tqdm(f, total=line_count):\n",
    "       blob = json.loads(line)\n",
    "       business_ids += [blob[\"business_id\"]]\n",
    "       name += [blob[\"name\"]]\n",
    "       city += [blob[\"city\"]]\n",
    "       avg_rating += [blob[\"stars\"]]\n",
    "       review_cnt += [blob[\"review_count\"]]\n",
    "       categories += [blob[\"categories\"]]\n",
    "       latitude += [blob[\"latitude\"]]\n",
    "       longitude += [blob[\"longitude\"]]\n",
    "       is_open += [blob[\"is_open\"]]\n",
    "       attributes += [blob['attributes']]\n",
    "business = pd.DataFrame(\n",
    "   {\"business_id\": business_ids, \"name\": name, \"city\": city, \"avg_rating\": avg_rating,\"review_cnt\": review_cnt,\n",
    "    \"categories\": categories, \"latitude\": latitude, \"longitude\": longitude, \"is_open\": is_open, \"attributes\": attributes}\n",
    ")\n",
    "\n",
    "\n",
    "#Imporing User data\n",
    "\n",
    "line_count = len(open(\"../data/user.json\").readlines())\n",
    "user_id, review_cnt, yelping_since, useful, funny, cool, fans, avg_user_rating, yrs_elite, \\\n",
    "compliment_hot, compliment_more, compliment_profile, compliment_cute, compliment_list, \\\n",
    "compliment_note, compliment_plain, compliment_cool, \\\n",
    "compliment_funny, compliment_writer, compliment_photos = [], [], [], [],[], [], [], [], [],[], [], [], [], [],[], [], [], [], [],[] \n",
    "\n",
    "with open(\"user.json\") as f:\n",
    "  for line in tqdm(f, total=line_count):\n",
    "       blob = json.loads(line)\n",
    "       user_id += [blob[\"user_id\"]]\n",
    "       review_cnt += [blob[\"review_count\"]]\n",
    "       yelping_since += [blob[\"yelping_since\"]]\n",
    "       useful += [blob[\"useful\"]]\n",
    "       funny += [blob[\"funny\"]]\n",
    "       cool += [blob[\"cool\"]]\n",
    "       fans += [blob[\"fans\"]]\n",
    "       avg_user_rating += [blob[\"average_stars\"]]\n",
    "       yrs_elite += [blob[\"elite\"]]\n",
    "       compliment_hot += [blob['compliment_hot']]\n",
    "       compliment_more += [blob['compliment_more']]\n",
    "       compliment_profile += [blob['compliment_profile']]\n",
    "       compliment_cute += [blob['compliment_cute']]\n",
    "       compliment_list += [blob['compliment_list']]\n",
    "       compliment_note += [blob['compliment_note']]\n",
    "       compliment_plain += [blob['compliment_plain']]\n",
    "       compliment_funny += [blob['compliment_funny']]\n",
    "       compliment_writer += [blob['compliment_writer']]\n",
    "       compliment_photos += [blob['compliment_photos']]\n",
    "user = pd.DataFrame(\n",
    "   {\"user_id\": user_id, \"review_cnt\": review_cnt, \"yelping_since\": yelping_since, \"useful\": useful,\"funny\": funny,\n",
    "    \"cool\": cool, \"fans\": fans, \"avg_user_rating\": avg_user_rating, \"yrs_elite\": yrs_elite, \"compliment_hot\": compliment_hot,\n",
    "    \"compliment_more\": compliment_more, \"compliment_profile\": compliment_profile, \"compliment_cute\": compliment_cute,\n",
    "   \"compliment_list\": compliment_list, \"compliment_note\": compliment_note, \"compliment_plain\": compliment_plain,\n",
    "   \"compliment_funny\": compliment_funny, \"compliment_writer\": compliment_writer, \"compliment_photos\": compliment_photos}\n",
    ")\n",
    "\n",
    "\n",
    "#Calculating number of years since elite\n",
    "user['years_elite'] = user['yrs_elite'].str.split(',').apply(lambda x: np.where(x==[''],0,len(x)))\n",
    "\n",
    "\n",
    "#Merging ratings and business data\n",
    "data_1=ratings.merge(business,how='left',on='business_id')\n",
    "\n",
    "#Merging ratings,business and user data\n",
    "data_1=data_1.merge(user,how='left',on='user_id')\n",
    "\n",
    "#Filtering data using date\n",
    "data_1['date']=pd.to_datetime(data_1['date'])\n",
    "data_1=data_1[data_1.date>'2017-01-01']\n",
    "\n",
    "#Filtering on city and Restaurants\n",
    "data_2=data_1[(data_1.categories.str.contains('Restaurants',na=False)) & (data_1.city==\"Las Vegas\")]\n",
    "\n",
    "user_counts=data_2['user_id'].value_counts()\n",
    "active_users = user_counts.loc[user_counts >= 5].index.tolist()\n",
    "\n",
    "data_2=data_2[(data_2.user_id.isin(active_users))]\n",
    "\n",
    "#Converting the categories to columns (One-hot encoded)\n",
    "categorylist = data_2['categories'].tolist()\n",
    "categories = [st.split(', ') for st in categorylist]\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "categoryarray = mlb.fit_transform(categories)\n",
    "names = mlb.classes_\n",
    "cat_df = pd.DataFrame(categoryarray,columns=names)\n",
    "cat_df\n",
    "merged_data = pd.concat([data_2.reset_index(),cat_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_dict_to_list(str1,str2,str3,merged_data):\n",
    "    list1=[]\n",
    "    for i in merged_data.index:\n",
    "        try:\n",
    "            list1.append(int(literal_eval(merged_data[str1][i][str2])[str3]))\n",
    "        except:\n",
    "            list1.append(0)\n",
    "    return(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['garage']=function_dict_to_list('attributes','BusinessParking','garage',merged_data)\n",
    "merged_data['street']=function_dict_to_list('attributes','BusinessParking','street',merged_data)\n",
    "merged_data['lot']=function_dict_to_list('attributes','BusinessParking','lot',merged_data)\n",
    "merged_data['valet']=function_dict_to_list('attributes','BusinessParking','valet',merged_data)\n",
    "merged_data['validated']=function_dict_to_list('attributes','BusinessParking','validated',merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_single_values(str1,str2,merged_data):\n",
    "    list1=[]\n",
    "    for i in merged_data.index:\n",
    "        try:\n",
    "            list1.append(int(merged_data[str1][i][str2]))\n",
    "        except:\n",
    "            list1.append(0)\n",
    "    return(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['OutdoorSeating']=function_single_values('attributes','OutdoorSeating',merged_data)\n",
    "merged_data['RestaurantsTakeOut']=function_single_values('attributes','RestaurantsTakeOut',merged_data)\n",
    "merged_data['HasTV']=function_single_values('attributes','HasTV',merged_data)\n",
    "merged_data['GoodForKids']=function_single_values('attributes','GoodForKids',merged_data)\n",
    "merged_data['RestaurantsReservations']=function_single_values('attributes','RestaurantsReservations',merged_data)\n",
    "merged_data['BusinessAcceptsCreditCards']=function_single_values('attributes','BusinessAcceptsCreditCards',merged_data)\n",
    "merged_data['RestaurantsPriceRange2']=function_single_values('attributes','RestaurantsPriceRange2',merged_data)\n",
    "merged_data['BusinessAcceptsCreditCards']=function_single_values('attributes','BusinessAcceptsCreditCards',merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['dessert']=function_dict_to_list('attributes','GoodForMeal','dessert',merged_data)\n",
    "merged_data['lunch']=function_dict_to_list('attributes','GoodForMeal','lunch',merged_data)\n",
    "merged_data['brunch']=function_dict_to_list('attributes','GoodForMeal','brunch',merged_data)\n",
    "merged_data['breakfast']=function_dict_to_list('attributes','GoodForMeal','breakfast',merged_data)\n",
    "merged_data['latenight']=function_dict_to_list('attributes','GoodForMeal','latenight',merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['romantic']=function_dict_to_list('attributes','Ambience','romantic',merged_data)\n",
    "merged_data['upscale']=function_dict_to_list('attributes','Ambience','upscale',merged_data)\n",
    "merged_data['intimate']=function_dict_to_list('attributes','Ambience','intimate',merged_data)\n",
    "merged_data['hipster']=function_dict_to_list('attributes','Ambience','hipster',merged_data)\n",
    "merged_data['casual']=function_dict_to_list('attributes','Ambience','casual',merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_csv('../data/merged_data_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating number of years since elite\n",
    "user['years_elite'] = user['yrs_elite'].str.split(',').apply(lambda x: np.where(x==[''],0,len(x)))\n",
    "\n",
    "\n",
    "#Merging ratings and business data\n",
    "data_1=ratings.merge(business,how='left',on='business_id')\n",
    "\n",
    "#Merging ratings,business and user data\n",
    "data_1=data_1.merge(user,how='left',on='user_id')\n",
    "\n",
    "#Filtering data using date\n",
    "data_1['date']=pd.to_datetime(data_1['date'])\n",
    "data_1=data_1[data_1.date>'2014-01-01']\n",
    "\n",
    "#Filtering on city and Restaurants\n",
    "data_2=data_1[(data_1.categories.str.contains('Restaurants',na=False)) & (data_1.city==\"Las Vegas\")]\n",
    "\n",
    "user_counts=data_2['user_id'].value_counts()\n",
    "active_users = user_counts.loc[user_counts >= 5].index.tolist()\n",
    "\n",
    "data_2=data_2[(data_2.user_id.isin(active_users))]\n",
    "\n",
    "#Converting the categories to columns (One-hot encoded)\n",
    "categorylist = data_2['categories'].tolist()\n",
    "categories = [st.split(', ') for st in categorylist]\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "categoryarray = mlb.fit_transform(categories)\n",
    "names = mlb.classes_\n",
    "cat_df = pd.DataFrame(categoryarray,columns=names)\n",
    "cat_df\n",
    "merged_data = pd.concat([data_2.reset_index(),cat_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_dict_to_list(str1,str2,str3,merged_data):\n",
    "    list1=[]\n",
    "    for i in merged_data.index:\n",
    "        try:\n",
    "            list1.append(int(literal_eval(merged_data[str1][i][str2])[str3]))\n",
    "        except:\n",
    "            list1.append(0)\n",
    "    return(list1)\n",
    "\n",
    "merged_data['garage']=function_dict_to_list('attributes','BusinessParking','garage',merged_data)\n",
    "merged_data['street']=function_dict_to_list('attributes','BusinessParking','street',merged_data)\n",
    "merged_data['lot']=function_dict_to_list('attributes','BusinessParking','lot',merged_data)\n",
    "merged_data['valet']=function_dict_to_list('attributes','BusinessParking','valet',merged_data)\n",
    "merged_data['validated']=function_dict_to_list('attributes','BusinessParking','validated',merged_data)\n",
    "\n",
    "def function_single_values(str1,str2,merged_data):\n",
    "    list1=[]\n",
    "    for i in merged_data.index:\n",
    "        try:\n",
    "            list1.append(int(merged_data[str1][i][str2]))\n",
    "        except:\n",
    "            list1.append(0)\n",
    "    return(list1)\n",
    "\n",
    "merged_data['OutdoorSeating']=function_single_values('attributes','OutdoorSeating',merged_data)\n",
    "merged_data['RestaurantsTakeOut']=function_single_values('attributes','RestaurantsTakeOut',merged_data)\n",
    "merged_data['HasTV']=function_single_values('attributes','HasTV',merged_data)\n",
    "merged_data['GoodForKids']=function_single_values('attributes','GoodForKids',merged_data)\n",
    "merged_data['RestaurantsReservations']=function_single_values('attributes','RestaurantsReservations',merged_data)\n",
    "merged_data['BusinessAcceptsCreditCards']=function_single_values('attributes','BusinessAcceptsCreditCards',merged_data)\n",
    "merged_data['RestaurantsPriceRange2']=function_single_values('attributes','RestaurantsPriceRange2',merged_data)\n",
    "merged_data['BusinessAcceptsCreditCards']=function_single_values('attributes','BusinessAcceptsCreditCards',merged_data)\n",
    "\n",
    "merged_data['dessert']=function_dict_to_list('attributes','GoodForMeal','dessert',merged_data)\n",
    "merged_data['lunch']=function_dict_to_list('attributes','GoodForMeal','lunch',merged_data)\n",
    "merged_data['brunch']=function_dict_to_list('attributes','GoodForMeal','brunch',merged_data)\n",
    "merged_data['breakfast']=function_dict_to_list('attributes','GoodForMeal','breakfast',merged_data)\n",
    "merged_data['latenight']=function_dict_to_list('attributes','GoodForMeal','latenight',merged_data)\n",
    "\n",
    "merged_data['romantic']=function_dict_to_list('attributes','Ambience','romantic',merged_data)\n",
    "merged_data['upscale']=function_dict_to_list('attributes','Ambience','upscale',merged_data)\n",
    "merged_data['intimate']=function_dict_to_list('attributes','Ambience','intimate',merged_data)\n",
    "merged_data['hipster']=function_dict_to_list('attributes','Ambience','hipster',merged_data)\n",
    "merged_data['casual']=function_dict_to_list('attributes','Ambience','casual',merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_csv('../data/merged_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
