{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from pytorch_widedeep.preprocessing import WidePreprocessor, DeepPreprocessor, TextPreprocessor, ImagePreprocessor\n",
    "from pytorch_widedeep.models import Wide, DeepDense, DeepText, DeepImage, WideDeep\n",
    "from pytorch_widedeep.initializers import *\n",
    "from pytorch_widedeep.callbacks import *\n",
    "from pytorch_widedeep.optim import RAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from pyfm import pylibfm\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../data/merged_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_small=pd.read_csv(\"../data/merged_data_small.csv\")\n",
    "dataset=dataset[dataset_small.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset created\n",
      "train dataset created\n"
     ]
    }
   ],
   "source": [
    "test_dataset = dataset[dataset.groupby('user_id')['date'].transform('max') == dataset['date']].reset_index(drop=True)\n",
    "print(\"test dataset created\")\n",
    "train_dataset = pd.concat([dataset, test_dataset]).drop_duplicates(keep=False).reset_index(drop=True)\n",
    "print(\"train dataset created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_dummies=list(train_dataset.columns)[34:-11]+list(train_dataset.columns)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_cols=['is_open']+already_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'rating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_dataset[target_col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "wide_preprocessor = WidePreprocessor(wide_cols=wide_cols)\n",
    "X_wide_train = wide_preprocessor.fit_transform(train_dataset)\n",
    "X_wide_test = wide_preprocessor.transform(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_embed_cols = [(c, 16) for c in train_dataset.columns if 'city' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_cols = ['useful',\n",
    " 'funny',\n",
    " 'cool',\n",
    " 'fans',\n",
    " 'avg_user_rating',\n",
    " 'compliment_hot',\n",
    " 'compliment_more',\n",
    " 'compliment_profile',\n",
    " 'compliment_cute',\n",
    " 'compliment_list',\n",
    " 'compliment_note',\n",
    " 'compliment_plain',\n",
    " 'compliment_funny',\n",
    " 'compliment_writer',\n",
    " 'compliment_photos',\n",
    " 'years_elite',\n",
    "'review_cnt_x','review_cnt_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_preprocessor = DeepPreprocessor(embed_cols=cat_embed_cols, continuous_cols=continuous_cols)\n",
    "X_deep_train = deep_preprocessor.fit_transform(train_dataset)\n",
    "X_deep_test = deep_preprocessor.fit_transform(test_dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_function(list1,list2):\n",
    "\n",
    "    # Linear model\n",
    "    wide = Wide(wide_dim=X_wide_train.shape[1], output_dim=1)\n",
    "    # DeepDense: 2 Dense layers\n",
    "    deepdense = DeepDense(hidden_layers=list1, dropout=list2,batchnorm=True, \n",
    "                      deep_column_idx=deep_preprocessor.deep_column_idx,\n",
    "                      embed_input=deep_preprocessor.embeddings_input,\n",
    "                      continuous_cols=continuous_cols)\n",
    "    \n",
    "    model = WideDeep(wide=wide, deepdense=deepdense)\n",
    "    model.compile(method='regression')\n",
    "    model.fit(X_wide=X_wide_train, X_deep=X_deep_train,target=target, n_epochs=5, batch_size=64, val_split=0.3)\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4376 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 4376/4376 [00:51<00:00, 84.43it/s, loss=1.21]\n",
      "valid: 100%|██████████| 1876/1876 [00:17<00:00, 106.23it/s, loss=1.18]\n",
      "epoch 2: 100%|██████████| 4376/4376 [00:50<00:00, 86.25it/s, loss=1.18] \n",
      "valid: 100%|██████████| 1876/1876 [00:13<00:00, 135.49it/s, loss=1.18]\n",
      "epoch 3: 100%|██████████| 4376/4376 [00:47<00:00, 92.42it/s, loss=1.18] \n",
      "valid: 100%|██████████| 1876/1876 [00:13<00:00, 137.56it/s, loss=1.18]\n",
      "epoch 4: 100%|██████████| 4376/4376 [00:47<00:00, 113.12it/s, loss=1.18]\n",
      "valid: 100%|██████████| 1876/1876 [00:13<00:00, 148.45it/s, loss=1.18]\n",
      "epoch 5: 100%|██████████| 4376/4376 [00:47<00:00, 92.47it/s, loss=1.18] \n",
      "valid: 100%|██████████| 1876/1876 [00:13<00:00, 139.64it/s, loss=1.18]\n"
     ]
    }
   ],
   "source": [
    "model_1=deep_function([32,32],[0.5,0.5])\n",
    "model_2=deep_function([32,64],[0.5,0.5])\n",
    "model_3=deep_function([64,64],[0.5,0.5])\n",
    "model_4=deep_function([64,128],[0.5,0.5])\n",
    "model_5=deep_function([32,32,32],[0.5,0.5,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_function(model):\n",
    "    y_pred=model.predict(X_wide=X_wide_test, X_deep=X_deep_test)\n",
    "    rmse = sqrt(mean_squared_error(test_dataset[target_col].values, y_pred))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "l.append(rmse_function(model_1))\n",
    "l.append(rmse_function(model_2))\n",
    "l.append(rmse_function(model_3))\n",
    "l.append(rmse_function(model_4))\n",
    "l.append(rmse_function(model_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2=['32 x 32','32 x 64','64 x 64','64 x 128','32 x 32 x 32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(l2,l)\n",
    "plt.title(\"Plot of RMSE vs Number of Neurons in each hidden layer\")\n",
    "plt.xlabel(\"No of Neurons\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.savefig('../output/' +'rmse_hidden_layers.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_function(model):\n",
    "    y_pred=model.predict(X_wide=X_wide_test, X_deep=X_deep_test)\n",
    "    mae = sqrt(mean_absolute_error(test_dataset[target_col].values, y_pred))\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "l.append(mae_function(model_1))\n",
    "l.append(mae_function(model_2))\n",
    "l.append(mae_function(model_3))\n",
    "l.append(mae_function(model_4))\n",
    "l.append(mae_function(model_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(l2,l)\n",
    "plt.title(\"Plot of Mae vs Number of Neurons in each hidden layer\")\n",
    "plt.xlabel(\"No of Neurons\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.savefig('../output/' +'mae_hidden_layers.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_counts=dataset['user_id'].value_counts()\n",
    "less_prolific_users = user_counts.loc[user_counts <= 5].index.tolist()\n",
    "test_data_less_prolific=test_dataset[(test_dataset.user_id.isin(less_prolific_users))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_wide_test_less_prolific = wide_preprocessor.transform(test_data_less_prolific)\n",
    "X_deep_test_less_prolific = deep_preprocessor.fit_transform(test_data_less_prolific) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 100%|██████████| 143/143 [00:00<00:00, 192.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error for less prolific users = 1.2515044661420935\n"
     ]
    }
   ],
   "source": [
    "y_pred=model_5.predict(X_wide=X_wide_test_less_prolific, X_deep=X_deep_test_less_prolific)\n",
    "rmse = sqrt(mean_squared_error(test_data_less_prolific[target_col].values, y_pred))\n",
    "print(\"Root-mean-square error for less prolific users = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_counts=dataset['business_id'].value_counts()\n",
    "less_popular_business = business_counts.loc[business_counts <= 100].index.tolist()\n",
    "test_data_less_popular=test_dataset[(test_dataset.business_id.isin(less_popular_business))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_wide_test_less_popular = wide_preprocessor.transform(test_data_less_popular)\n",
    "X_deep_test_less_popular = deep_preprocessor.fit_transform(test_data_less_popular) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 100%|██████████| 165/165 [00:00<00:00, 211.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error for less popular business = 1.371823946487629\n"
     ]
    }
   ],
   "source": [
    "y_pred=model_5.predict(X_wide=X_wide_test_less_popular, X_deep=X_deep_test_less_popular)\n",
    "rmse = sqrt(mean_squared_error(test_data_less_popular[target_col].values, y_pred))\n",
    "print(\"Root-mean-square error for less popular business = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 100%|██████████| 7790/7790 [00:35<00:00, 234.49it/s]\n"
     ]
    }
   ],
   "source": [
    "user_data_1=dataset[['user_id','useful',\n",
    " 'funny',\n",
    " 'cool',\n",
    " 'fans',\n",
    " 'avg_user_rating',\n",
    " 'compliment_hot',\n",
    " 'compliment_more',\n",
    " 'compliment_profile',\n",
    " 'compliment_cute',\n",
    " 'compliment_list',\n",
    " 'compliment_note',\n",
    " 'compliment_plain',\n",
    " 'compliment_funny',\n",
    " 'compliment_writer',\n",
    " 'compliment_photos',\n",
    " 'years_elite',\n",
    "'review_cnt_y']]\n",
    "\n",
    "\n",
    "user_data_1[user_data_1['user_id']=='3CJUJILq7CLHk_9OrvpvQg']\n",
    "user_data_1=user_data_1.drop_duplicates(subset=None, keep='first', inplace=False)\n",
    "\n",
    "business_data_1=dataset[['business_id']+['review_cnt_x']+['city']+['name']+['categories']+wide_cols]\n",
    "business_data_1=business_data_1.drop_duplicates(subset=None, keep='first', inplace=False)\n",
    "\n",
    "from itertools import product\n",
    "combination=list(product(dataset['user_id'].unique()[1:1000], dataset['business_id'].unique()[1:500]))\n",
    "\n",
    "df_pred_1=pd.DataFrame(data=combination,columns=['user_id','business_id'])\n",
    "\n",
    "\n",
    "df_pred_1=df_pred_1.merge(user_data_1,how='left',on='user_id')\n",
    "\n",
    "df_pred_1=df_pred_1.merge(business_data_1,how='left',on='business_id')\n",
    "\n",
    "X_wide_pred = wide_preprocessor.transform(df_pred_1)\n",
    "X_deep_pred = deep_preprocessor.fit_transform(df_pred_1) \n",
    "\n",
    "y_pred_1=model_5.predict(X_wide=X_wide_pred, X_deep=X_deep_pred)\n",
    "\n",
    "df_pred_1['predicted_rating']=y_pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User coverage on test set: 96.996996996997\n",
      "Catalogue coverage on test set: 12.83\n"
     ]
    }
   ],
   "source": [
    "df_pred_1=df_pred_1.sort_values(['user_id', 'predicted_rating'], ascending=[True, False])\n",
    "\n",
    "df_pred_1['RN'] = df_pred_1.sort_values(['user_id','predicted_rating'], ascending=[True,False]) \\\n",
    "             .groupby(['user_id']) \\\n",
    "             .cumcount() + 1\n",
    "\n",
    "df_pred_2=df_pred_1.loc[df_pred_1['RN'].isin(range(1,11))].reset_index(drop=True)\n",
    "\n",
    "#User Coverage\n",
    "def user_coverage(data,k,threshold):\n",
    "    sum1=0\n",
    "    l1=[]\n",
    "    c=0\n",
    "    for i in range(0,df_pred_2.shape[0]):\n",
    "        if(df_pred_2['predicted_rating'][i] > 3.5):\n",
    "            l1.append(1)\n",
    "            c+=1\n",
    "        else:\n",
    "            l1.append(0)\n",
    "            c+=1\n",
    "        if(c == 10):\n",
    "            if (np.sum(l1) > 5):\n",
    "                sum1+=1\n",
    "            c=0\n",
    "            l1=[]\n",
    "    user_coverage=sum1/df_pred_2['user_id'].nunique()*100\n",
    "    return(user_coverage)\n",
    "coverage_1_test=user_coverage(df_pred_2,5,3.5)\n",
    "print('User coverage on test set:',coverage_1_test)\n",
    "\n",
    "\n",
    "#Catalogue Coverage\n",
    "def catalogue_coverage(predicted, catalog):\n",
    "    predicted_flattened = [p for sublist in predicted for p in sublist]\n",
    "    unique_predictions = len(set(predicted_flattened))\n",
    "    prediction_coverage = round(unique_predictions/(len(catalog)* 1.0)*100,2)\n",
    "    return prediction_coverage\n",
    "coverage_2=catalogue_coverage(list(df_pred_2['business_id']),list(df_pred_1['business_id'].unique()))\n",
    "print('Catalogue coverage on test set:',coverage_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_3=df_pred_2.merge(business_data_1[['business_id','name']],how='left',on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name_y</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6sK3CL1g1OP1FMawX2hxA</td>\n",
       "      <td>Fountains of Bellagio</td>\n",
       "      <td>Public Services &amp; Government, Restaurants, Per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-6sK3CL1g1OP1FMawX2hxA</td>\n",
       "      <td>Blue Ribbon Brasserie - Las  Vegas</td>\n",
       "      <td>Cocktail Bars, Restaurants, Seafood, Comfort F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6sK3CL1g1OP1FMawX2hxA</td>\n",
       "      <td>Eatt Gourmet Bistro</td>\n",
       "      <td>Fast Food, Restaurants, Sandwiches, Bakeries, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6sK3CL1g1OP1FMawX2hxA</td>\n",
       "      <td>The Corndog Company LV</td>\n",
       "      <td>Food Trucks, Street Vendors, Food, Hot Dogs, R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6sK3CL1g1OP1FMawX2hxA</td>\n",
       "      <td>The Venetian Las Vegas</td>\n",
       "      <td>Shopping Centers, Resorts, Arts &amp; Entertainmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-6sK3CL1g1OP1FMawX2hxA</td>\n",
       "      <td>Azuza Hookah Lounge &amp; Cafe</td>\n",
       "      <td>Beer, Wine &amp; Spirits, Bars, Ethnic Food, Cafes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-6sK3CL1g1OP1FMawX2hxA</td>\n",
       "      <td>Tina's Gourmet Sausage House</td>\n",
       "      <td>Specialty Food, Butcher, Delis, International ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-6sK3CL1g1OP1FMawX2hxA</td>\n",
       "      <td>Pinball Hall Of Fame</td>\n",
       "      <td>Performing Arts, Amusement Parks, Museums, Arc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-6sK3CL1g1OP1FMawX2hxA</td>\n",
       "      <td>The Steakhouse at Treasures</td>\n",
       "      <td>Cocktail Bars, Food, Wineries, Nightlife, Rest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-6sK3CL1g1OP1FMawX2hxA</td>\n",
       "      <td>Estiatorio Milos</td>\n",
       "      <td>Seafood, Greek, Restaurants</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id                              name_y  \\\n",
       "0  -6sK3CL1g1OP1FMawX2hxA               Fountains of Bellagio   \n",
       "1  -6sK3CL1g1OP1FMawX2hxA  Blue Ribbon Brasserie - Las  Vegas   \n",
       "2  -6sK3CL1g1OP1FMawX2hxA                 Eatt Gourmet Bistro   \n",
       "3  -6sK3CL1g1OP1FMawX2hxA              The Corndog Company LV   \n",
       "4  -6sK3CL1g1OP1FMawX2hxA              The Venetian Las Vegas   \n",
       "5  -6sK3CL1g1OP1FMawX2hxA          Azuza Hookah Lounge & Cafe   \n",
       "6  -6sK3CL1g1OP1FMawX2hxA        Tina's Gourmet Sausage House   \n",
       "7  -6sK3CL1g1OP1FMawX2hxA                Pinball Hall Of Fame   \n",
       "8  -6sK3CL1g1OP1FMawX2hxA         The Steakhouse at Treasures   \n",
       "9  -6sK3CL1g1OP1FMawX2hxA                    Estiatorio Milos   \n",
       "\n",
       "                                          categories  \n",
       "0  Public Services & Government, Restaurants, Per...  \n",
       "1  Cocktail Bars, Restaurants, Seafood, Comfort F...  \n",
       "2  Fast Food, Restaurants, Sandwiches, Bakeries, ...  \n",
       "3  Food Trucks, Street Vendors, Food, Hot Dogs, R...  \n",
       "4  Shopping Centers, Resorts, Arts & Entertainmen...  \n",
       "5  Beer, Wine & Spirits, Bars, Ethnic Food, Cafes...  \n",
       "6  Specialty Food, Butcher, Delis, International ...  \n",
       "7  Performing Arts, Amusement Parks, Museums, Arc...  \n",
       "8  Cocktail Bars, Food, Wineries, Nightlife, Rest...  \n",
       "9                        Seafood, Greek, Restaurants  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_3[['user_id','name_y','categories']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>-6sK3CL1g1OP1FMawX2hxA</td>\n",
       "      <td>Capriotti's Sandwich Shop</td>\n",
       "      <td>Restaurants, Delis, Sandwiches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45976</th>\n",
       "      <td>-6sK3CL1g1OP1FMawX2hxA</td>\n",
       "      <td>Wicked Spoon</td>\n",
       "      <td>Buffets, Breakfast &amp; Brunch, Restaurants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167083</th>\n",
       "      <td>-6sK3CL1g1OP1FMawX2hxA</td>\n",
       "      <td>Taco Bell</td>\n",
       "      <td>Food, Restaurants, Tex-Mex, Mexican, Fast Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224919</th>\n",
       "      <td>-6sK3CL1g1OP1FMawX2hxA</td>\n",
       "      <td>Lotus of Siam</td>\n",
       "      <td>Car Dealers, Nightlife, Automotive, Buffets, W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338517</th>\n",
       "      <td>-6sK3CL1g1OP1FMawX2hxA</td>\n",
       "      <td>Delhi Indian Cuisine</td>\n",
       "      <td>Halal, Restaurants, Buffets, Food, Indian, Foo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363125</th>\n",
       "      <td>-6sK3CL1g1OP1FMawX2hxA</td>\n",
       "      <td>Pho Vegas</td>\n",
       "      <td>Vietnamese, Soup, Restaurants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404365</th>\n",
       "      <td>-6sK3CL1g1OP1FMawX2hxA</td>\n",
       "      <td>The Buffet</td>\n",
       "      <td>Beauty &amp; Spas, Food, Event Planning &amp; Services...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418877</th>\n",
       "      <td>-6sK3CL1g1OP1FMawX2hxA</td>\n",
       "      <td>Mr Sandwich</td>\n",
       "      <td>Juice Bars &amp; Smoothies, Sandwiches, Vietnamese...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       user_id                       name  \\\n",
       "412     -6sK3CL1g1OP1FMawX2hxA  Capriotti's Sandwich Shop   \n",
       "45976   -6sK3CL1g1OP1FMawX2hxA               Wicked Spoon   \n",
       "167083  -6sK3CL1g1OP1FMawX2hxA                  Taco Bell   \n",
       "224919  -6sK3CL1g1OP1FMawX2hxA              Lotus of Siam   \n",
       "338517  -6sK3CL1g1OP1FMawX2hxA       Delhi Indian Cuisine   \n",
       "363125  -6sK3CL1g1OP1FMawX2hxA                  Pho Vegas   \n",
       "404365  -6sK3CL1g1OP1FMawX2hxA                 The Buffet   \n",
       "418877  -6sK3CL1g1OP1FMawX2hxA                Mr Sandwich   \n",
       "\n",
       "                                               categories  \n",
       "412                        Restaurants, Delis, Sandwiches  \n",
       "45976            Buffets, Breakfast & Brunch, Restaurants  \n",
       "167083     Food, Restaurants, Tex-Mex, Mexican, Fast Food  \n",
       "224919  Car Dealers, Nightlife, Automotive, Buffets, W...  \n",
       "338517  Halal, Restaurants, Buffets, Food, Indian, Foo...  \n",
       "363125                      Vietnamese, Soup, Restaurants  \n",
       "404365  Beauty & Spas, Food, Event Planning & Services...  \n",
       "418877  Juice Bars & Smoothies, Sandwiches, Vietnamese...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[['user_id','name','categories']].loc[dataset['user_id']=='-6sK3CL1g1OP1FMawX2hxA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_3[['user_id','name_y','categories']].head(10).to_csv('../output/recommended.csv')\n",
    "dataset[['user_id','name','categories']].loc[dataset['user_id']=='-6sK3CL1g1OP1FMawX2hxA'].to_csv('../output/actual_visited.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
